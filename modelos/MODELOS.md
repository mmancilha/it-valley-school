# ğŸ¤– Modelos de Machine Learning - AnÃ¡lise de EmoÃ§Ãµes

## ğŸ¯ VisÃ£o Geral dos Modelos

Esta pasta contÃ©m a **implementaÃ§Ã£o completa** de diferentes algoritmos de machine learning para **anÃ¡lise de sentimentos e emoÃ§Ãµes** em texto. O projeto demonstra a evoluÃ§Ã£o progressiva de modelos, desde regressÃ£o logÃ­stica bÃ¡sica atÃ© redes neurais profundas.

### ğŸš€ Objetivo Principal
Classificar automaticamente textos como **"Feliz" (Happy)** ou **"Triste" (Sad)** usando diferentes abordagens de machine learning e comparar suas performances.

---

## ğŸ“Š Modelos Implementados

### ğŸ”¢ **1. RegressÃ£o LogÃ­stica** (`1 - linear_model.py`)
- **Tipo**: Modelo linear clÃ¡ssico
- **Algoritmo**: Logistic Regression
- **VetorizaÃ§Ã£o**: CountVectorizer (Bag of Words)
- **Performance**: Baseline do projeto
- **Vantagens**: Simples, interpretÃ¡vel, rÃ¡pido
- **Dataset**: 12 frases em portuguÃªs

```python
# Exemplo de uso
frases = ["Estou muito feliz hoje!", "Isso me deixa muito triste."]
rotulos = [1, 0]  # 1=alegria, 0=tristeza
```

### ğŸ¯ **2. Support Vector Machine** (`3 - modelo-svm.py`)
- **Tipo**: Classificador baseado em margens
- **Algoritmo**: SVM com kernel RBF
- **VetorizaÃ§Ã£o**: TF-IDF ou CountVectorizer
- **Performance**: Melhoria sobre regressÃ£o logÃ­stica
- **Vantagens**: Eficaz para datasets pequenos, robusto

### ğŸŒ³ **3. Random Forest** (`5 - RandonForest.py`)
- **Tipo**: Ensemble de Ã¡rvores de decisÃ£o
- **Algoritmo**: Random Forest Classifier
- **Performance**: +34% melhoria sobre baseline
- **Vantagens**: Melhor modelo de ML tradicional
- **CaracterÃ­sticas**: Reduz overfitting, fornece importÃ¢ncia das features

### ğŸ§  **4. Deep Learning MLP** (`4 - DeepLearningMLP.py`)
- **Tipo**: Rede Neural Profunda
- **Framework**: TensorFlow/Keras
- **Arquitetura**: Multi-Layer Perceptron
- **Performance**: +51% melhoria sobre baseline
- **Vantagens**: Melhor modelo geral, captura padrÃµes complexos

### âš™ï¸ **5. ConfiguraÃ§Ã£o de ParÃ¢metros** (`6 - parametrosEmotionIA.py`)
- **FunÃ§Ã£o**: OtimizaÃ§Ã£o de hiperparÃ¢metros
- **TÃ©cnicas**: Grid Search, Random Search
- **Objetivo**: Encontrar melhores configuraÃ§Ãµes para cada modelo
- **AplicaÃ§Ã£o**: Fine-tuning dos modelos implementados

### ğŸ­ **6. Modelo Principal** (`emotionAI_MLP.py`)
- **Tipo**: Modelo de produÃ§Ã£o otimizado
- **Base**: Deep Learning MLP refinado
- **Funcionalidades**: PrediÃ§Ã£o em tempo real
- **Interface**: FunÃ§Ã£o `predict_emotion(text)`
- **Threshold**: 0.5215 (otimizado para melhor classificaÃ§Ã£o)

---

## ğŸ“ Estrutura Detalhada dos Arquivos

### ğŸ **Scripts de Modelos**

#### ğŸ“ˆ **1 - linear_model.py** (Modelo Base)
```python
# CaracterÃ­sticas principais:
- Dataset: 12 frases em portuguÃªs
- VetorizaÃ§Ã£o: CountVectorizer (Bag of Words)
- Algoritmo: LogisticRegression
- DivisÃ£o: train_test_split
- MÃ©tricas: accuracy_score
```

#### ğŸ¯ **3 - modelo-svm.py** (SVM Classifier)
```python
# Melhorias implementadas:
- Kernel RBF para padrÃµes nÃ£o-lineares
- VetorizaÃ§Ã£o TF-IDF mais sofisticada
- RegularizaÃ§Ã£o automÃ¡tica
- Melhor generalizaÃ§Ã£o
```

#### ğŸŒ² **5 - RandonForest.py** (Ensemble Method)
```python
# CaracterÃ­sticas avanÃ§adas:
- MÃºltiplas Ã¡rvores de decisÃ£o
- VotaÃ§Ã£o por maioria
- Feature importance analysis
- ReduÃ§Ã£o de overfitting
- +34% performance boost
```

#### ğŸ§  **4 - DeepLearningMLP.py** (Neural Network)
```python
# Arquitetura neural:
- Camadas densas com ativaÃ§Ã£o ReLU
- Dropout para regularizaÃ§Ã£o
- Otimizador Adam
- Loss: binary_crossentropy
- +51% performance improvement
```

#### âš¡ **emotionAI_MLP.py** (Modelo de ProduÃ§Ã£o)
```python
# Funcionalidades de produÃ§Ã£o:
def predict_emotion(text):
    prediction = EmotionIA.predict(text_vectorized)[0][0]
    return prediction, "Happy ğŸ˜" if prediction > 0.5215 else "Sad ğŸ˜¢"
```

---

## ğŸš€ Pipeline de Desenvolvimento

### ğŸ“‹ **Fluxo de Trabalho**
1. **Modelo Base** â†’ RegressÃ£o LogÃ­stica (baseline)
2. **OtimizaÃ§Ã£o** â†’ SVM com kernel RBF
3. **Ensemble** â†’ Random Forest (+34% performance)
4. **Deep Learning** â†’ MLP (+51% performance)
5. **ProduÃ§Ã£o** â†’ Modelo otimizado com threshold ajustado

### ğŸ”„ **Processo de Treinamento**
```python
# Pipeline padrÃ£o para todos os modelos:
1. Carregamento de dados (frases + rÃ³tulos)
2. VetorizaÃ§Ã£o de texto (CountVectorizer/TF-IDF)
3. DivisÃ£o treino/teste (train_test_split)
4. Treinamento do modelo
5. AvaliaÃ§Ã£o de performance
6. Salvamento do modelo treinado
```

---

## ğŸ“ˆ ComparaÃ§Ã£o de Performance

### ğŸ† **Ranking dos Modelos**
| PosiÃ§Ã£o | Modelo | Performance | Melhoria |
|---------|--------|-------------|----------|
| ğŸ¥‡ | **Deep Learning MLP** | Melhor | +51% |
| ğŸ¥ˆ | **Random Forest** | Muito Boa | +34% |
| ğŸ¥‰ | **SVM** | Boa | +15% |
| 4Âº | **RegressÃ£o LogÃ­stica** | Baseline | 0% |

### ğŸ“Š **MÃ©tricas Detalhadas**
- **AcurÃ¡cia**: Percentual de prediÃ§Ãµes corretas
- **Tempo de Treinamento**: Velocidade de aprendizado
- **Tempo de PrediÃ§Ã£o**: Velocidade de classificaÃ§Ã£o
- **Complexidade**: Recursos computacionais necessÃ¡rios

---

## ğŸ› ï¸ Como Executar os Modelos

### ğŸ“‹ **PrÃ©-requisitos**
```bash
# Instalar dependÃªncias
pip install scikit-learn tensorflow pandas numpy
```

### âš¡ **ExecuÃ§Ã£o Individual**
```bash
# Navegar para a pasta
cd modelos/

# 1. Modelo baseline (RegressÃ£o LogÃ­stica)
python "1 - linear_model.py"

# 2. SVM Classifier
python "3 - modelo-svm.py"

# 3. Random Forest
python "5 - RandonForest.py"

# 4. Deep Learning MLP
python "4 - DeepLearningMLP.py"

# 5. OtimizaÃ§Ã£o de parÃ¢metros
python "6 - parametrosEmotionIA.py"

# 6. Modelo de produÃ§Ã£o
python "emotionAI_MLP.py"
```

### ğŸ¯ **Uso do Modelo Principal**
```python
# Importar e usar o modelo otimizado
from emotionAI_MLP import predict_emotion

# Testar prediÃ§Ãµes
texto = "Estou muito feliz hoje!"
score, emocao = predict_emotion(texto)
print(f"Texto: {texto}")
print(f"EmoÃ§Ã£o: {emocao} (Score: {score:.4f})")
```

---

## ğŸ§  Detalhes TÃ©cnicos AvanÃ§ados

### ğŸ”¤ **Processamento de Texto**

#### **CountVectorizer (Bag of Words)**
```python
# Transforma texto em matriz de contagem de palavras
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(frases).toarray()
```

#### **TF-IDF Vectorization**
```python
# Considera importÃ¢ncia relativa das palavras
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf = TfidfVectorizer()
```

### ğŸ¯ **OtimizaÃ§Ã£o de Threshold**
```python
# Threshold otimizado para melhor classificaÃ§Ã£o
threshold = 0.5215  # Ajustado empiricamente
emotion = "Happy ğŸ˜" if prediction > threshold else "Sad ğŸ˜¢"
```

### ğŸ§ª **ValidaÃ§Ã£o e Testes**
```python
# Frases de teste padrÃ£o
test_sentences = [
    "I feel amazing today!",  # Esperado: Happy
    "Everything is falling apart",  # Esperado: Sad
    "This is the happiest moment of my life",  # Esperado: Happy
    "I feel completely lost"  # Esperado: Sad
]
```

---

## ğŸ“š Conceitos de Machine Learning Demonstrados

### âœ… **Algoritmos Implementados**
- **RegressÃ£o LogÃ­stica**: ClassificaÃ§Ã£o linear
- **SVM**: ClassificaÃ§Ã£o baseada em margens
- **Random Forest**: Ensemble learning
- **Deep Learning**: Redes neurais artificiais

### âœ… **TÃ©cnicas de Processamento**
- **VetorizaÃ§Ã£o de Texto**: CountVectorizer, TF-IDF
- **DivisÃ£o de Dados**: train_test_split
- **AvaliaÃ§Ã£o**: accuracy_score, mÃ©tricas customizadas
- **OtimizaÃ§Ã£o**: Grid search, threshold tuning

### âœ… **Boas PrÃ¡ticas**
- **ComparaÃ§Ã£o de Modelos**: Benchmarking sistemÃ¡tico
- **EvoluÃ§Ã£o Progressiva**: Do simples ao complexo
- **Modelo de ProduÃ§Ã£o**: CÃ³digo otimizado para uso real
- **DocumentaÃ§Ã£o**: CÃ³digo bem comentado

---

## ğŸ“ Valor Educacional

### ğŸ“– **Aprendizados Principais**
1. **ProgressÃ£o Natural**: Como evoluir de modelos simples para complexos
2. **ComparaÃ§Ã£o PrÃ¡tica**: Performance real de diferentes algoritmos
3. **ImplementaÃ§Ã£o Completa**: Do treinamento Ã  produÃ§Ã£o
4. **OtimizaÃ§Ã£o**: Como melhorar performance de modelos

### ğŸ¯ **AplicaÃ§Ãµes PrÃ¡ticas**
- **AnÃ¡lise de Sentimentos**: Redes sociais, reviews, feedback
- **Chatbots**: DetecÃ§Ã£o de emoÃ§Ãµes em conversas
- **Monitoramento**: AnÃ¡lise automÃ¡tica de satisfaÃ§Ã£o
- **Pesquisa**: Estudos de opiniÃ£o e comportamento

---

## ğŸš€ PrÃ³ximos Passos e Melhorias

### ğŸ”„ **ExpansÃµes PossÃ­veis**
1. **Mais EmoÃ§Ãµes**: Expandir para raiva, medo, surpresa, etc.
2. **Datasets Maiores**: Usar bases de dados mais robustas
3. **Modelos AvanÃ§ados**: BERT, GPT, Transformers
4. **Interface Web**: AplicaÃ§Ã£o interativa para testes
5. **API REST**: ServiÃ§o web para integraÃ§Ã£o

### ğŸ“Š **Melhorias TÃ©cnicas**
- **Cross-Validation**: ValidaÃ§Ã£o cruzada mais robusta
- **Feature Engineering**: ExtraÃ§Ã£o de caracterÃ­sticas avanÃ§adas
- **Ensemble Methods**: CombinaÃ§Ã£o de mÃºltiplos modelos
- **Real-time Processing**: OtimizaÃ§Ã£o para tempo real

---

## ğŸ”— IntegraÃ§Ã£o com o Projeto Principal

Este mÃ³dulo de **modelos** Ã© o **coraÃ§Ã£o tÃ©cnico** do projeto IT Valley School, demonstrando:

- ğŸ¯ **EvoluÃ§Ã£o de Modelos**: ProgressÃ£o natural do aprendizado
- ğŸ“Š **ComparaÃ§Ã£o PrÃ¡tica**: Performance real de diferentes abordagens
- ğŸš€ **ImplementaÃ§Ã£o Completa**: Do conceito Ã  produÃ§Ã£o
- ğŸ§  **Deep Learning**: Estado da arte em anÃ¡lise de emoÃ§Ãµes

### ğŸ† **Resultado Final**
O **Deep Learning MLP** com **+51% de melhoria** representa o estado da arte do projeto, demonstrando o poder das redes neurais para anÃ¡lise de sentimentos e emoÃ§Ãµes em texto.